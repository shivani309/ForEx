{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open_price</th>\n",
       "      <th>Day_high</th>\n",
       "      <th>Day_low</th>\n",
       "      <th>Closing_price</th>\n",
       "      <th>Currency Pair</th>\n",
       "      <th>Trend_Open_price</th>\n",
       "      <th>Seasonal_Open_price</th>\n",
       "      <th>Residual_Open_price</th>\n",
       "      <th>...</th>\n",
       "      <th>Seasonal_Day_low</th>\n",
       "      <th>Residual_Day_low</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_Signal</th>\n",
       "      <th>BB_Upper</th>\n",
       "      <th>BB_Lower</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000000</th>\n",
       "      <td>0</td>\n",
       "      <td>2014-11-07</td>\n",
       "      <td>0.386891</td>\n",
       "      <td>0.384657</td>\n",
       "      <td>0.389693</td>\n",
       "      <td>0.386954</td>\n",
       "      <td>USD/INR</td>\n",
       "      <td>0.394461</td>\n",
       "      <td>0.522182</td>\n",
       "      <td>0.60751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473615</td>\n",
       "      <td>0.538767</td>\n",
       "      <td>64.491363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.391812</td>\n",
       "      <td>0.38654</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000055</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-11-10</td>\n",
       "      <td>0.387590</td>\n",
       "      <td>0.384752</td>\n",
       "      <td>0.389693</td>\n",
       "      <td>0.387558</td>\n",
       "      <td>USD/INR</td>\n",
       "      <td>0.394461</td>\n",
       "      <td>0.557718</td>\n",
       "      <td>0.60751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460915</td>\n",
       "      <td>0.538767</td>\n",
       "      <td>64.491363</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.391812</td>\n",
       "      <td>0.38654</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000109</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-11-11</td>\n",
       "      <td>0.387781</td>\n",
       "      <td>0.384248</td>\n",
       "      <td>0.390750</td>\n",
       "      <td>0.387641</td>\n",
       "      <td>USD/INR</td>\n",
       "      <td>0.394461</td>\n",
       "      <td>0.533733</td>\n",
       "      <td>0.60751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475153</td>\n",
       "      <td>0.538767</td>\n",
       "      <td>64.491363</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.391812</td>\n",
       "      <td>0.38654</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000164</th>\n",
       "      <td>3</td>\n",
       "      <td>2014-11-12</td>\n",
       "      <td>0.387641</td>\n",
       "      <td>0.384280</td>\n",
       "      <td>0.389757</td>\n",
       "      <td>0.386897</td>\n",
       "      <td>USD/INR</td>\n",
       "      <td>0.394461</td>\n",
       "      <td>0.541190</td>\n",
       "      <td>0.60751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422273</td>\n",
       "      <td>0.538767</td>\n",
       "      <td>64.491363</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.391812</td>\n",
       "      <td>0.38654</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000219</th>\n",
       "      <td>4</td>\n",
       "      <td>2014-11-13</td>\n",
       "      <td>0.386752</td>\n",
       "      <td>0.384676</td>\n",
       "      <td>0.389757</td>\n",
       "      <td>0.388003</td>\n",
       "      <td>USD/INR</td>\n",
       "      <td>0.394461</td>\n",
       "      <td>0.534029</td>\n",
       "      <td>0.60751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456504</td>\n",
       "      <td>0.538767</td>\n",
       "      <td>64.491363</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.391812</td>\n",
       "      <td>0.38654</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0.1        Date  Open_price  Day_high   Day_low  \\\n",
       "Unnamed: 0                                                             \n",
       "0.000000               0  2014-11-07    0.386891  0.384657  0.389693   \n",
       "0.000055               1  2014-11-10    0.387590  0.384752  0.389693   \n",
       "0.000109               2  2014-11-11    0.387781  0.384248  0.390750   \n",
       "0.000164               3  2014-11-12    0.387641  0.384280  0.389757   \n",
       "0.000219               4  2014-11-13    0.386752  0.384676  0.389757   \n",
       "\n",
       "            Closing_price Currency Pair  Trend_Open_price  \\\n",
       "Unnamed: 0                                                  \n",
       "0.000000         0.386954       USD/INR          0.394461   \n",
       "0.000055         0.387558       USD/INR          0.394461   \n",
       "0.000109         0.387641       USD/INR          0.394461   \n",
       "0.000164         0.386897       USD/INR          0.394461   \n",
       "0.000219         0.388003       USD/INR          0.394461   \n",
       "\n",
       "            Seasonal_Open_price  Residual_Open_price  ...  Seasonal_Day_low  \\\n",
       "Unnamed: 0                                            ...                     \n",
       "0.000000               0.522182              0.60751  ...          0.473615   \n",
       "0.000055               0.557718              0.60751  ...          0.460915   \n",
       "0.000109               0.533733              0.60751  ...          0.475153   \n",
       "0.000164               0.541190              0.60751  ...          0.422273   \n",
       "0.000219               0.534029              0.60751  ...          0.456504   \n",
       "\n",
       "            Residual_Day_low        RSI      MACD  MACD_Signal  BB_Upper  \\\n",
       "Unnamed: 0                                                                 \n",
       "0.000000            0.538767  64.491363  0.000000     0.000000  0.391812   \n",
       "0.000055            0.538767  64.491363  0.000048     0.000010  0.391812   \n",
       "0.000109            0.538767  64.491363  0.000092     0.000026  0.391812   \n",
       "0.000164            0.538767  64.491363  0.000066     0.000034  0.391812   \n",
       "0.000219            0.538767  64.491363  0.000133     0.000054  0.391812   \n",
       "\n",
       "            BB_Lower  day_of_week  month  is_weekend  \n",
       "Unnamed: 0                                            \n",
       "0.000000     0.38654            4     11           0  \n",
       "0.000055     0.38654            0     11           0  \n",
       "0.000109     0.38654            1     11           0  \n",
       "0.000164     0.38654            2     11           0  \n",
       "0.000219     0.38654            3     11           0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'C:/Users/uzmap/Documents/GitHub/ForEx/data_For_prophet.csv',index_col='Unnamed: 0')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for currency pair: USD/INR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:40:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:40:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for currency pair: EUR/USD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:40:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:40:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for currency pair: GBP/USD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:40:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:40:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for currency pair: USD/JPY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:40:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:40:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for currency pair: EUR/INR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:40:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:40:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "17:40:17 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for currency pair: JPY/INR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:40:18 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for currency pair: GBP/INR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:40:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:40:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results for Each Currency Pair:\n",
      "USD/INR - Train: MAE: 0.000689587683939987, MAPE: 0.0015613995472382107, R^2: 0.9991214520708618\n",
      "Test: MAE: 0.002532717698598882, MAPE: 0.004838223636468014, R^2: 0.3250390477967763\n",
      "Difference in R² (Train - Test): 0.6740824042740855\n",
      "True values (sample): [0.51128423 0.51189428 0.51432814 0.51519238 0.51543386]\n",
      "Predicted values (sample): [0.50290394 0.50348122 0.51263309 0.5136242  0.51461454]\n",
      "\n",
      "EUR/USD - Train: MAE: 1.9750040484407092e-05, MAPE: 0.005131994942927224, R^2: 0.9893266914957639\n",
      "Test: MAE: 5.074404420918985e-05, MAPE: 0.013904686268811847, R^2: 0.6257269309711652\n",
      "Difference in R² (Train - Test): 0.36359976052459875\n",
      "True values (sample): [0.00335682 0.00338039 0.00335923 0.00333966 0.00328552]\n",
      "Predicted values (sample): [0.00332713 0.00336176 0.00337825 0.0034516  0.00344386]\n",
      "\n",
      "GBP/USD - Train: MAE: 3.586474522425106e-05, MAPE: 0.006813605727640526, R^2: 0.9804772712521642\n",
      "Test: MAE: 2.680812377791883e-05, MAPE: 0.005659609397651212, R^2: 0.972727082110634\n",
      "Difference in R² (Train - Test): 0.00775018914153025\n",
      "True values (sample): [0.00432432 0.0043465  0.00431148 0.00432813 0.00429077]\n",
      "Predicted values (sample): [0.00427948 0.00431527 0.00433545 0.00432755 0.00431116]\n",
      "\n",
      "USD/JPY - Train: MAE: 0.0018337348402159873, MAPE: 0.0025369886670644566, R^2: 0.9978456062415838\n",
      "Test: MAE: 0.007098101591222587, MAPE: 0.00822857864529917, R^2: 0.932533423908117\n",
      "Difference in R² (Train - Test): 0.0653121823334668\n",
      "True values (sample): [0.87985774 0.88212644 0.88905302 0.88804268 0.89976713]\n",
      "Predicted values (sample): [0.88577728 0.88268366 0.88392402 0.88760195 0.89475847]\n",
      "\n",
      "EUR/INR - Train: MAE: 0.001227135874368022, MAPE: 0.0024840838895693303, R^2: 0.9980665724045633\n",
      "Test: MAE: 0.0032816331980577967, MAPE: 0.005775920594550114, R^2: 0.8819573019470577\n",
      "Difference in R² (Train - Test): 0.11610927045750563\n",
      "True values (sample): [0.52847882 0.53027593 0.53501655 0.53444081 0.5321976 ]\n",
      "Predicted values (sample): [0.52181013 0.52432607 0.53071413 0.53297048 0.53291326]\n",
      "\n",
      "JPY/INR - Train: MAE: 1.1493355862591917e-05, MAPE: 25693149.193599913, R^2: 0.997994136675569\n",
      "Test: MAE: 3.637663998610223e-05, MAPE: 0.11421077775300957, R^2: 0.9220136193549995\n",
      "Difference in R² (Train - Test): 0.07598051732056954\n",
      "True values (sample): [0.00046256 0.00045214 0.00047419 0.0004862  0.00047247]\n",
      "Predicted values (sample): [0.00040023 0.00035019 0.00037627 0.0004748  0.00047704]\n",
      "\n",
      "GBP/INR - Train: MAE: 0.0016540774364813386, MAPE: 0.002813997447670442, R^2: 0.9963846373023956\n",
      "Test: MAE: 0.0021739035439281257, MAPE: 0.003302822711979323, R^2: 0.9824729097059616\n",
      "Difference in R² (Train - Test): 0.013911727596433998\n",
      "True values (sample): [0.60157267 0.60794581 0.61339117 0.61195055 0.61299463]\n",
      "Predicted values (sample): [0.60072338 0.6046647  0.60584454 0.60828199 0.61028102]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "# Convert Date column to datetime (if necessary)\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# List of unique currency pairs\n",
    "currency_pairs = data['Currency Pair'].unique()\n",
    "\n",
    "# Dictionary to store evaluation metrics for each currency pair\n",
    "results = {}\n",
    "\n",
    "# Loop over each currency pair\n",
    "for pair in currency_pairs:\n",
    "    print(f\"Training model for currency pair: {pair}\")\n",
    "    \n",
    "    # Filter data for the current currency pair\n",
    "    pair_data = data[data['Currency Pair'] == pair]\n",
    "    \n",
    "    # Sort by date to ensure proper time series order\n",
    "    pair_data = pair_data.sort_values('Date')\n",
    "    \n",
    "    # Prepare data for Prophet (needs columns 'ds' and 'y')\n",
    "    df_prophet = pair_data[['Date', 'Closing_price']].rename(columns={'Date': 'ds', 'Closing_price': 'y'})\n",
    "    \n",
    "    # Add the regressors to the data (these are assumed to be already in the dataset)\n",
    "    regressors = [\n",
    "        'RSI', 'MACD', 'MACD_Signal', 'BB_Upper', 'BB_Lower', \n",
    "        'is_weekend', 'Seasonal_Open_price'\n",
    "    ]\n",
    "    \n",
    "    for regressor in regressors:\n",
    "        df_prophet[regressor] = pair_data[regressor]\n",
    "    \n",
    "    # Split data into train and test sets (80-20 split)\n",
    "    split_idx = int(len(df_prophet) * 0.8)\n",
    "    train_data = df_prophet.iloc[:split_idx]\n",
    "    test_data = df_prophet.iloc[split_idx:]\n",
    "    \n",
    "    # Initialize the Prophet model and add regressors\n",
    "    model = Prophet(daily_seasonality=True, yearly_seasonality=True, weekly_seasonality=True)\n",
    "    \n",
    "    # Add each regressor to the model\n",
    "    for regressor in regressors:\n",
    "        model.add_regressor(regressor)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(train_data)\n",
    "\n",
    "    # Make future DataFrame for predictions (including the regressors)\n",
    "    future = model.make_future_dataframe(periods=len(test_data), freq='D')\n",
    "    \n",
    "    # Add the regressors to the future DataFrame\n",
    "    for regressor in regressors:\n",
    "        future[regressor] = pair_data[regressor].iloc[-len(future):].values\n",
    "    \n",
    "    # Forecast using Prophet\n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    # Extract the forecasted values for the training and test periods\n",
    "    y_pred_train = forecast['yhat'].iloc[:split_idx].values\n",
    "    y_train = train_data['y'].values\n",
    "    \n",
    "    y_pred_test = forecast['yhat'].iloc[split_idx:].values\n",
    "    y_test = test_data['y'].values\n",
    "\n",
    "    # Calculate evaluation metrics for training data\n",
    "    mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "    mape_train = mean_absolute_percentage_error(y_train, y_pred_train)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    \n",
    "    # Calculate evaluation metrics for test data\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    mape_test = mean_absolute_percentage_error(y_test, y_pred_test)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "    # Calculate difference in R² between training and test to check for overfitting\n",
    "    r2_difference = r2_train - r2_test\n",
    "    \n",
    "    # Store the results and predictions for this currency pair\n",
    "    results[pair] = {\n",
    "        'MAE_train': mae_train,\n",
    "        'MAPE_train': mape_train,\n",
    "        'R^2_train': r2_train,\n",
    "        'MAE_test': mae_test,\n",
    "        'MAPE_test': mape_test,\n",
    "        'R^2_test': r2_test,\n",
    "        'R^2_difference': r2_difference,\n",
    "        'y_true_test': y_test,       # True values for the test set\n",
    "        'y_pred_test': y_pred_test    # Predicted values for the test set\n",
    "    }\n",
    "\n",
    "# Display final results and predictions for each currency pair\n",
    "print(\"\\nFinal Results for Each Currency Pair:\")\n",
    "for pair, metrics in results.items():\n",
    "    print(f\"{pair} - Train: MAE: {metrics['MAE_train']}, MAPE: {metrics['MAPE_train']}, R^2: {metrics['R^2_train']}\")\n",
    "    print(f\"Test: MAE: {metrics['MAE_test']}, MAPE: {metrics['MAPE_test']}, R^2: {metrics['R^2_test']}\")\n",
    "    print(f\"Difference in R² (Train - Test): {metrics['R^2_difference']}\")\n",
    "    print(f\"True values (sample): {metrics['y_true_test'][:5]}\")\n",
    "    print(f\"Predicted values (sample): {metrics['y_pred_test'][:5]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prophet with XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for currency pair: USD/INR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:41:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:41:25 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for currency pair: EUR/USD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:41:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:41:27 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for currency pair: GBP/USD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:41:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:41:28 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for currency pair: USD/JPY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:41:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:41:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for currency pair: EUR/INR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:41:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:41:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for currency pair: JPY/INR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:41:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:41:35 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for currency pair: GBP/INR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:41:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:41:38 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results for Each Currency Pair:\n",
      "USD/INR - Train: MAE: 0.0005673028571944296, MAPE: 0.001291290831304136, R^2: 0.9994246616362678\n",
      "Test: MAE: 0.0026293276657167403, MAPE: 0.005023193288588003, R^2: 0.20502774044305316\n",
      "Difference in R² (Train - Test): 0.7943969211932146\n",
      "True values (sample): [0.51128423 0.51189428 0.51432814 0.51519238 0.51543386]\n",
      "Predicted values (sample): [0.50181487 0.50251188 0.5117108  0.51265706 0.51365996]\n",
      "\n",
      "EUR/USD - Train: MAE: 1.9750043401254852e-05, MAPE: 0.005131998054123242, R^2: 0.9893266915749953\n",
      "Test: MAE: 5.0745888461136485e-05, MAPE: 0.013905189660229501, R^2: 0.6257048750447303\n",
      "Difference in R² (Train - Test): 0.36362181653026504\n",
      "True values (sample): [0.00335682 0.00338039 0.00335923 0.00333966 0.00328552]\n",
      "Predicted values (sample): [0.00332713 0.00336177 0.00337826 0.0034516  0.00344386]\n",
      "\n",
      "GBP/USD - Train: MAE: 3.586477205745934e-05, MAPE: 0.006813611313640423, R^2: 0.9804772712650194\n",
      "Test: MAE: 2.680863695017618e-05, MAPE: 0.0056597228181537, R^2: 0.9727261706825544\n",
      "Difference in R² (Train - Test): 0.007751100582464976\n",
      "True values (sample): [0.00432432 0.0043465  0.00431148 0.00432813 0.00429077]\n",
      "Predicted values (sample): [0.00427948 0.00431527 0.00433545 0.00432755 0.00431115]\n",
      "\n",
      "USD/JPY - Train: MAE: 0.0013204861363882608, MAPE: 0.00184236053832517, R^2: 0.9989753419355462\n",
      "Test: MAE: 0.007730092382290952, MAPE: 0.008850017673079844, R^2: 0.934812206041111\n",
      "Difference in R² (Train - Test): 0.06416313589443512\n",
      "True values (sample): [0.87985774 0.88212644 0.88905302 0.88804268 0.89976713]\n",
      "Predicted values (sample): [0.88143673 0.87640394 0.87811958 0.88206    0.88914687]\n",
      "\n",
      "EUR/INR - Train: MAE: 0.0009125260992954488, MAPE: 0.0018429199052261587, R^2: 0.9989543463890452\n",
      "Test: MAE: 0.003925253237165586, MAPE: 0.006902860561839763, R^2: 0.8358875349638681\n",
      "Difference in R² (Train - Test): 0.1630668114251771\n",
      "True values (sample): [0.52847882 0.53027593 0.53501655 0.53444081 0.5321976 ]\n",
      "Predicted values (sample): [0.52212436 0.52437666 0.53096376 0.5334159  0.53270358]\n",
      "\n",
      "JPY/INR - Train: MAE: 1.1493357008966633e-05, MAPE: 25693212.932028893, R^2: 0.9979941366755762\n",
      "Test: MAE: 3.6376619691862805e-05, MAPE: 0.11421070652647754, R^2: 0.9220136768365383\n",
      "Difference in R² (Train - Test): 0.0759804598390379\n",
      "True values (sample): [0.00046256 0.00045214 0.00047419 0.0004862  0.00047247]\n",
      "Predicted values (sample): [0.00040023 0.00035019 0.00037627 0.0004748  0.00047704]\n",
      "\n",
      "GBP/INR - Train: MAE: 0.0011438839928040391, MAPE: 0.001945623387345424, R^2: 0.998414372904494\n",
      "Test: MAE: 0.0022585892160491075, MAPE: 0.003432105593009771, R^2: 0.9814550193053455\n",
      "Difference in R² (Train - Test): 0.016959353599148463\n",
      "True values (sample): [0.60157267 0.60794581 0.61339117 0.61195055 0.61299463]\n",
      "Predicted values (sample): [0.60185505 0.60467106 0.60550971 0.60850891 0.60949903]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Convert Date column to datetime (if necessary)\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# List of unique currency pairs\n",
    "currency_pairs = data['Currency Pair'].unique()\n",
    "\n",
    "# Dictionary to store evaluation metrics for each currency pair\n",
    "results = {}\n",
    "\n",
    "# Loop over each currency pair\n",
    "for pair in currency_pairs:\n",
    "    print(f\"Training model for currency pair: {pair}\")\n",
    "    \n",
    "    # Filter data for the current currency pair\n",
    "    pair_data = data[data['Currency Pair'] == pair]\n",
    "    \n",
    "    # Sort by date to ensure proper time series order\n",
    "    pair_data = pair_data.sort_values('Date')\n",
    "    \n",
    "    # Prepare data for Prophet (needs columns 'ds' and 'y')\n",
    "    df_prophet = pair_data[['Date', 'Closing_price']].rename(columns={'Date': 'ds', 'Closing_price': 'y'})\n",
    "    \n",
    "    # Add the regressors to the data (these are assumed to be already in the dataset)\n",
    "    regressors = [\n",
    "        'RSI', 'MACD', 'MACD_Signal', 'BB_Upper', 'BB_Lower', \n",
    "        'is_weekend', 'Seasonal_Open_price'\n",
    "    ]\n",
    "    \n",
    "    for regressor in regressors:\n",
    "        df_prophet[regressor] = pair_data[regressor]\n",
    "    \n",
    "    # Split data into train and test sets (80-20 split)\n",
    "    split_idx = int(len(df_prophet) * 0.8)\n",
    "    train_data = df_prophet.iloc[:split_idx]\n",
    "    test_data = df_prophet.iloc[split_idx:]\n",
    "    \n",
    "    # Initialize the Prophet model and add regressors\n",
    "    model = Prophet(daily_seasonality=True, yearly_seasonality=True, weekly_seasonality=True)\n",
    "    \n",
    "    # Add each regressor to the model\n",
    "    for regressor in regressors:\n",
    "        model.add_regressor(regressor)\n",
    "    \n",
    "    # Fit the Prophet model\n",
    "    model.fit(train_data)\n",
    "    \n",
    "    # Create a DataFrame for training predictions with regressors\n",
    "    future_train = train_data[['ds']].copy()\n",
    "    for regressor in regressors:\n",
    "        future_train[regressor] = train_data[regressor]\n",
    "    \n",
    "    # Forecast using Prophet for training data\n",
    "    forecast_train = model.predict(future_train)\n",
    "    y_pred_train_prophet = forecast_train['yhat'].values\n",
    "    y_train = train_data['y'].values\n",
    "    \n",
    "    # Make future DataFrame for test predictions (including the regressors)\n",
    "    future_test = model.make_future_dataframe(periods=len(test_data), freq='D')\n",
    "    for regressor in regressors:\n",
    "        future_test[regressor] = pair_data[regressor].iloc[-len(future_test):].values\n",
    "    \n",
    "    # Forecast using Prophet for test data\n",
    "    forecast_test = model.predict(future_test)\n",
    "    y_pred_test_prophet = forecast_test['yhat'].iloc[split_idx:].values\n",
    "    y_test = test_data['y'].values\n",
    "    \n",
    "    # Calculate residuals for both training and test sets\n",
    "    residuals_train = y_train - y_pred_train_prophet\n",
    "    residuals_test = y_test - y_pred_test_prophet\n",
    "    \n",
    "    # Prepare XGBoost for residual correction on training data\n",
    "    xgboost_data_train = train_data[regressors].copy()\n",
    "    xgboost_data_train['residual'] = residuals_train\n",
    "    X_train = xgboost_data_train[regressors]\n",
    "    y_residual_train = xgboost_data_train['residual']\n",
    "    \n",
    "    # Prepare XGBoost for residual correction on test data\n",
    "    xgboost_data_test = test_data[regressors].copy()\n",
    "    xgboost_data_test['residual'] = residuals_test\n",
    "    X_test = xgboost_data_test[regressors]\n",
    "    y_residual_test = xgboost_data_test['residual']\n",
    "    \n",
    "    # Initialize the XGBoost model and fit it on the training residuals\n",
    "    xgboost_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.05, max_depth=6)\n",
    "    xgboost_model.fit(X_train, y_residual_train)\n",
    "    \n",
    "    # Predict residuals on both training and test sets\n",
    "    y_pred_residual_train = xgboost_model.predict(X_train)\n",
    "    y_pred_residual_test = xgboost_model.predict(X_test)\n",
    "    \n",
    "    # Combine Prophet and XGBoost predictions for both sets\n",
    "    y_pred_train_combined = y_pred_train_prophet + y_pred_residual_train\n",
    "    y_pred_test_combined = y_pred_test_prophet + y_pred_residual_test\n",
    "    \n",
    "    # Calculate evaluation metrics for training data\n",
    "    mae_train = mean_absolute_error(y_train, y_pred_train_combined)\n",
    "    mape_train = mean_absolute_percentage_error(y_train, y_pred_train_combined)\n",
    "    r2_train = r2_score(y_train, y_pred_train_combined)\n",
    "    \n",
    "    # Calculate evaluation metrics for test data\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test_combined)\n",
    "    mape_test = mean_absolute_percentage_error(y_test, y_pred_test_combined)\n",
    "    r2_test = r2_score(y_test, y_pred_test_combined)\n",
    "    \n",
    "    # Calculate difference in R² between training and test to check for overfitting\n",
    "    r2_difference = r2_train - r2_test\n",
    "    \n",
    "    # Store the results and predictions for this currency pair\n",
    "    results[pair] = {\n",
    "        'MAE_train': mae_train,\n",
    "        'MAPE_train': mape_train,\n",
    "        'R^2_train': r2_train,\n",
    "        'MAE_test': mae_test,\n",
    "        'MAPE_test': mape_test,\n",
    "        'R^2_test': r2_test,\n",
    "        'R^2_difference': r2_difference,\n",
    "        'y_true_test': y_test,         # True values for the test set\n",
    "        'y_pred_test': y_pred_test_combined  # Predicted values for the test set\n",
    "    }\n",
    "\n",
    "# Display final results for each currency pair\n",
    "print(\"\\nFinal Results for Each Currency Pair:\")\n",
    "for pair, metrics in results.items():\n",
    "    print(f\"{pair} - Train: MAE: {metrics['MAE_train']}, MAPE: {metrics['MAPE_train']}, R^2: {metrics['R^2_train']}\")\n",
    "    print(f\"Test: MAE: {metrics['MAE_test']}, MAPE: {metrics['MAPE_test']}, R^2: {metrics['R^2_test']}\")\n",
    "    print(f\"Difference in R² (Train - Test): {metrics['R^2_difference']}\")\n",
    "    print(f\"True values (sample): {metrics['y_true_test'][:5]}\")\n",
    "    print(f\"Predicted values (sample): {metrics['y_pred_test'][:5]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ARIMA model for currency pair: USD/INR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uzmap\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\uzmap\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\uzmap\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'The `start` argument could not be matched to a location related to the index of the data.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mindex.pyx:609\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1668384000000000000",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:577\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:611\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: Timestamp('2022-11-14 00:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\datetimes.py:630\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: Timestamp('2022-11-14 00:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:249\u001b[0m, in \u001b[0;36mget_index_label_loc\u001b[1;34m(key, index, row_labels)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger)):\n\u001b[1;32m--> 249\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[43mrow_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\datetimes.py:632\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 632\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(orig_key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: Timestamp('2022-11-14 00:00:00')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:358\u001b[0m, in \u001b[0;36mget_prediction_index\u001b[1;34m(start, end, nobs, base_index, index, silent, index_none, index_generated, data)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 358\u001b[0m     start, _, start_oos \u001b[38;5;241m=\u001b[39m \u001b[43mget_index_label_loc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrow_labels\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:281\u001b[0m, in \u001b[0;36mget_index_label_loc\u001b[1;34m(key, index, row_labels)\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loc, index, index_was_expanded\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:245\u001b[0m, in \u001b[0;36mget_index_label_loc\u001b[1;34m(key, index, row_labels)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 245\u001b[0m     loc, index, index_was_expanded \u001b[38;5;241m=\u001b[39m \u001b[43mget_index_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:195\u001b[0m, in \u001b[0;36mget_index_loc\u001b[1;34m(key, index)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 195\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[0;32m    196\u001b[0m loc \u001b[38;5;241m=\u001b[39m key\n",
      "\u001b[1;31mKeyError\u001b[0m: 'only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m model_fit\u001b[38;5;241m.\u001b[39mpredict(start\u001b[38;5;241m=\u001b[39mtrain_y\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m0\u001b[39m], end\u001b[38;5;241m=\u001b[39mtrain_y\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], exog\u001b[38;5;241m=\u001b[39mtrain_X)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# For test predictions, use the start and end index of the test data\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m y_pred_test \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_fit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Calculate evaluation metrics for both training and test sets\u001b[39;00m\n\u001b[0;32m     56\u001b[0m mae_train \u001b[38;5;241m=\u001b[39m mean_absolute_error(train_y, y_pred_train)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\base\\wrapper.py:113\u001b[0m, in \u001b[0;36mmake_wrapper.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m     obj \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mwrap_output(func(results, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), how[\u001b[38;5;241m0\u001b[39m], how[\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m how:\n\u001b[1;32m--> 113\u001b[0m     obj \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mwrap_output(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, how)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3488\u001b[0m, in \u001b[0;36mMLEResults.predict\u001b[1;34m(self, start, end, dynamic, information_set, signal_only, **kwargs)\u001b[0m\n\u001b[0;32m   3423\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3424\u001b[0m \u001b[38;5;124;03mIn-sample prediction and out-of-sample forecasting\u001b[39;00m\n\u001b[0;32m   3425\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3485\u001b[0m \u001b[38;5;124;03m    including confidence intervals.\u001b[39;00m\n\u001b[0;32m   3486\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3487\u001b[0m \u001b[38;5;66;03m# Perform the prediction\u001b[39;00m\n\u001b[1;32m-> 3488\u001b[0m prediction_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_prediction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minformation_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minformation_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3490\u001b[0m \u001b[43m    \u001b[49m\u001b[43msignal_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignal_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3491\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction_results\u001b[38;5;241m.\u001b[39mpredicted_mean\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3341\u001b[0m, in \u001b[0;36mMLEResults.get_prediction\u001b[1;34m(self, start, end, dynamic, information_set, signal_only, index, exog, extend_model, extend_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   3337\u001b[0m     start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3339\u001b[0m \u001b[38;5;66;03m# Handle start, end, dynamic\u001b[39;00m\n\u001b[0;32m   3340\u001b[0m start, end, out_of_sample, prediction_index \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 3341\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_prediction_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   3343\u001b[0m \u001b[38;5;66;03m# Handle `dynamic`\u001b[39;00m\n\u001b[0;32m   3344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dynamic, (\u001b[38;5;28mstr\u001b[39m, dt\u001b[38;5;241m.\u001b[39mdatetime, pd\u001b[38;5;241m.\u001b[39mTimestamp)):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837\u001b[0m, in \u001b[0;36mTimeSeriesModel._get_prediction_index\u001b[1;34m(self, start, end, index, silent)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;124;03mGet the location of a specific key in an index or model row labels\u001b[39;00m\n\u001b[0;32m    783\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;124;03msince we have required them to be full indexes, there is no ambiguity).\u001b[39;00m\n\u001b[0;32m    835\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    836\u001b[0m nobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog)\n\u001b[1;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_prediction_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_none\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_generated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_generated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:362\u001b[0m, in \u001b[0;36mget_prediction_index\u001b[1;34m(start, end, nobs, base_index, index, silent, index_none, index_generated, data)\u001b[0m\n\u001b[0;32m    358\u001b[0m     start, _, start_oos \u001b[38;5;241m=\u001b[39m get_index_label_loc(\n\u001b[0;32m    359\u001b[0m         start, base_index, data\u001b[38;5;241m.\u001b[39mrow_labels\n\u001b[0;32m    360\u001b[0m     )\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `start` argument could not be matched to a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m location related to the index of the data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m     )\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    367\u001b[0m     end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(start, \u001b[38;5;28mlen\u001b[39m(base_index) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'The `start` argument could not be matched to a location related to the index of the data.'"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Convert Date column to datetime (if necessary)\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# List of unique currency pairs\n",
    "currency_pairs = data['Currency Pair'].unique()\n",
    "\n",
    "# Dictionary to store evaluation metrics for each currency pair\n",
    "results = {}\n",
    "\n",
    "# Loop over each currency pair\n",
    "for pair in currency_pairs:\n",
    "    print(f\"Training ARIMA model for currency pair: {pair}\")\n",
    "    \n",
    "    # Filter data for the current currency pair\n",
    "    pair_data = data[data['Currency Pair'] == pair]\n",
    "    \n",
    "    # Sort by date to ensure proper time series order\n",
    "    pair_data = pair_data.sort_values('Date')\n",
    "    \n",
    "    # Prepare data for ARIMA (use 'Date' as index, and 'Closing_price' as target variable)\n",
    "    pair_data.set_index('Date', inplace=True)\n",
    "    y = pair_data['Closing_price']\n",
    "    \n",
    "    # Add any external regressors (additional features), such as RSI, MACD, etc.\n",
    "    regressors = [\n",
    "        'RSI', 'MACD', 'MACD_Signal', 'BB_Upper', 'BB_Lower', \n",
    "        'is_weekend','Seasonal_Open_price'\n",
    "    ]\n",
    "    \n",
    "    # Include regressors in the ARIMA model (ARIMAX)\n",
    "    X = pair_data[regressors]\n",
    "\n",
    "    # Split data into train and test sets (80-20 split)\n",
    "    split_idx = int(len(pair_data) * 0.8)\n",
    "    train_y = y[:split_idx]\n",
    "    test_y = y[split_idx:]\n",
    "    train_X = X[:split_idx]\n",
    "    test_X = X[split_idx:]\n",
    "    \n",
    "    # Fit ARIMA model with ARIMAX (ARIMA with exogenous variables)\n",
    "    model = ARIMA(train_y, exog=train_X, order=(5, 1, 0))  # (p, d, q) order of the ARIMA model\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    # Make predictions on both the training and test sets\n",
    "    # For training predictions, use the first and last index of the training data\n",
    "    y_pred_train = model_fit.predict(start=train_y.index[0], end=train_y.index[-1], exog=train_X)\n",
    "    \n",
    "    # For test predictions, use the start and end index of the test data\n",
    "    y_pred_test = model_fit.predict(start=test_y.index[0], end=test_y.index[-1], exog=test_X)\n",
    "\n",
    "    # Calculate evaluation metrics for both training and test sets\n",
    "    mae_train = mean_absolute_error(train_y, y_pred_train)\n",
    "    mape_train = mean_absolute_percentage_error(train_y, y_pred_train)\n",
    "    r2_train = r2_score(train_y, y_pred_train)\n",
    "    \n",
    "    mae_test = mean_absolute_error(test_y, y_pred_test)\n",
    "    mape_test = mean_absolute_percentage_error(test_y, y_pred_test)\n",
    "    r2_test = r2_score(test_y, y_pred_test)\n",
    "    \n",
    "    # Calculate the difference in R² between training and test to check for overfitting\n",
    "    r2_difference = r2_train - r2_test\n",
    "    \n",
    "    # Store the results for this currency pair\n",
    "    results[pair] = {\n",
    "        'MAE_train': mae_train,\n",
    "        'MAPE_train': mape_train,\n",
    "        'R^2_train': r2_train,\n",
    "        'MAE_test': mae_test,\n",
    "        'MAPE_test': mape_test,\n",
    "        'R^2_test': r2_test,\n",
    "        'R^2_difference': r2_difference,\n",
    "        'y_true_test': test_y,       # True values for the test set\n",
    "        'y_pred_test': y_pred_test    # Predicted values for the test set\n",
    "    }\n",
    "    \n",
    "    print(f\"Results for {pair} -\")\n",
    "    print(f\"Train - MAE: {mae_train}, MAPE: {mape_train}, R^2: {r2_train}\")\n",
    "    print(f\"Test - MAE: {mae_test}, MAPE: {mape_test}, R^2: {r2_test}\")\n",
    "    print(f\"Difference in R² (Train - Test): {r2_difference}\\n\")\n",
    "\n",
    "# Display final results for training and test performance comparison\n",
    "print(\"\\nFinal Results for Each Currency Pair:\")\n",
    "for pair, metrics in results.items():\n",
    "    print(f\"{pair} - Train: MAE: {metrics['MAE_train']}, MAPE: {metrics['MAPE_train']}, R^2: {metrics['R^2_train']}\")\n",
    "    print(f\"Test: MAE: {metrics['MAE_test']}, MAPE: {metrics['MAPE_test']}, R^2: {metrics['R^2_test']}\")\n",
    "    print(f\"Difference in R² (Train - Test): {metrics['R^2_difference']}\\n\")\n",
    "    print(f\"True values (sample): {metrics['y_true_test'][:5].values}\")\n",
    "    print(f\"Predicted values (sample): {metrics['y_pred_test'][:5].values}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Exponential Smoothing model for currency pair: USD/INR\n",
      "Training Exponential Smoothing model for currency pair: EUR/USD\n",
      "Training Exponential Smoothing model for currency pair: GBP/USD\n",
      "Training Exponential Smoothing model for currency pair: USD/JPY\n",
      "Training Exponential Smoothing model for currency pair: EUR/INR\n",
      "Training Exponential Smoothing model for currency pair: JPY/INR\n",
      "Training Exponential Smoothing model for currency pair: GBP/INR\n",
      "\n",
      "Final Results for Each Currency Pair:\n",
      "USD/INR - Train: MAE: 0.0011368392487149568, MAPE: 0.0025690282868317954, R^2: 0.9974903752905648\n",
      "Test: MAE: 0.015526178142636066, MAPE: 0.029572967353344606, R^2: -11.677360103145238\n",
      "Difference in R² (Train - Test): 12.674850478435804\n",
      "\n",
      "EUR/USD - Train: MAE: 3.0032883798454437e-05, MAPE: 0.00778736854206581, R^2: 0.9716360712374088\n",
      "Test: MAE: 0.00032227153142922414, MAPE: 0.08745413326759174, R^2: -8.800850608929341\n",
      "Difference in R² (Train - Test): 9.77248668016675\n",
      "\n",
      "GBP/USD - Train: MAE: 4.3869998379716616e-05, MAPE: 0.00840490851937003, R^2: 0.9497149750938912\n",
      "Test: MAE: 0.0005220800226045918, MAPE: 0.10785357531155494, R^2: -6.4409573703181255\n",
      "Difference in R² (Train - Test): 7.390672345412017\n",
      "\n",
      "USD/JPY - Train: MAE: 0.0027993799579745207, MAPE: 0.0038679919934118054, R^2: 0.9949223075855111\n",
      "Test: MAE: 0.052863420035757384, MAPE: 0.05928082673498303, R^2: -0.08790854252088787\n",
      "Difference in R² (Train - Test): 1.082830850106399\n",
      "\n",
      "EUR/INR - Train: MAE: 0.0020261272022163747, MAPE: 0.004100799322669443, R^2: 0.9945465460561991\n",
      "Test: MAE: 0.040439527165023526, MAPE: 0.07097260267453522, R^2: -13.6250742745226\n",
      "Difference in R² (Train - Test): 14.619620820578799\n",
      "\n",
      "JPY/INR - Train: MAE: 1.780324083918645e-05, MAPE: 88873898.32796627, R^2: 0.9948528345927642\n",
      "Test: MAE: 0.00015211154271129167, MAPE: 0.5398108869966568, R^2: -0.008984452354311001\n",
      "Difference in R² (Train - Test): 1.0038372869470753\n",
      "\n",
      "GBP/INR - Train: MAE: 0.002661021366296966, MAPE: 0.004524301809700399, R^2: 0.9907302544885916\n",
      "Test: MAE: 0.05719696868736133, MAPE: 0.08584435556510238, R^2: -7.5699687578852615\n",
      "Difference in R² (Train - Test): 8.560699012373853\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uzmap\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\uzmap\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "C:\\Users\\uzmap\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\uzmap\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "C:\\Users\\uzmap\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\uzmap\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "C:\\Users\\uzmap\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\uzmap\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "C:\\Users\\uzmap\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\uzmap\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "C:\\Users\\uzmap\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\uzmap\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "C:\\Users\\uzmap\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\uzmap\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Convert Date column to datetime (if necessary)\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# List of unique currency pairs\n",
    "currency_pairs = data['Currency Pair'].unique()\n",
    "\n",
    "# Dictionary to store evaluation metrics for each currency pair\n",
    "results = {}\n",
    "\n",
    "# Loop over each currency pair\n",
    "for pair in currency_pairs:\n",
    "    print(f\"Training Exponential Smoothing model for currency pair: {pair}\")\n",
    "    \n",
    "    # Filter data for the current currency pair\n",
    "    pair_data = data[data['Currency Pair'] == pair]\n",
    "    \n",
    "    # Sort by date to ensure proper time series order\n",
    "    pair_data = pair_data.sort_values('Date')\n",
    "    \n",
    "    # Prepare data (use 'Date' as index, and 'Closing_price' as target variable)\n",
    "    pair_data.set_index('Date', inplace=True)\n",
    "    y = pair_data['Closing_price']\n",
    "    \n",
    "    # Split data into train and test sets (80-20 split)\n",
    "    split_idx = int(len(pair_data) * 0.8)\n",
    "    train_y = y.iloc[:split_idx]\n",
    "    test_y = y.iloc[split_idx:]\n",
    "    \n",
    "    # Fit Exponential Smoothing model on the training set\n",
    "    model = ExponentialSmoothing(train_y)  # adjust for your data's seasonality\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    # Make predictions on the training set\n",
    "    y_pred_train = model_fit.fittedvalues\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred_test = model_fit.forecast(len(test_y))\n",
    "\n",
    "    # Calculate evaluation metrics for both training and test sets\n",
    "    mae_train = mean_absolute_error(train_y, y_pred_train)\n",
    "    mape_train = mean_absolute_percentage_error(train_y, y_pred_train)\n",
    "    r2_train = r2_score(train_y, y_pred_train)\n",
    "    \n",
    "    mae_test = mean_absolute_error(test_y, y_pred_test)\n",
    "    mape_test = mean_absolute_percentage_error(test_y, y_pred_test)\n",
    "    r2_test = r2_score(test_y, y_pred_test)\n",
    "    \n",
    "    # Calculate the difference in R² between training and test to check for overfitting\n",
    "    r2_difference = r2_train - r2_test\n",
    "    \n",
    "    # Store the results for this currency pair\n",
    "    results[pair] = {\n",
    "        'MAE_train': mae_train,\n",
    "        'MAPE_train': mape_train,\n",
    "        'R^2_train': r2_train,\n",
    "        'MAE_test': mae_test,\n",
    "        'MAPE_test': mape_test,\n",
    "        'R^2_test': r2_test,\n",
    "        'R^2_difference': r2_difference,\n",
    "        'y_true_test': test_y,       # True values for the test set\n",
    "        'y_pred_test': y_pred_test    # Predicted values for the test set\n",
    "    }\n",
    "\n",
    "# Display final results for training and test performance comparison\n",
    "print(\"\\nFinal Results for Each Currency Pair:\")\n",
    "for pair, metrics in results.items():\n",
    "    print(f\"{pair} - Train: MAE: {metrics['MAE_train']}, MAPE: {metrics['MAPE_train']}, R^2: {metrics['R^2_train']}\")\n",
    "    print(f\"Test: MAE: {metrics['MAE_test']}, MAPE: {metrics['MAPE_test']}, R^2: {metrics['R^2_test']}\")\n",
    "    print(f\"Difference in R² (Train - Test): {metrics['R^2_difference']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
